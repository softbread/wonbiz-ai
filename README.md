# Wonbiz AI - Voice Assistant & Note Taking App

<div align="center">
  <img width="1200" height="475" alt="Wonbiz AI Banner" src="https://github.com/user-attachments/assets/0aa67016-6eaf-458a-adb2-6e31a0763ed6" />
</div>

<p align="center">
  <strong>A modern voice assistant that transcribes, summarizes, and organizes your thoughts using AI</strong>
</p>

<p align="center">
  <a href="#features">Features</a> â€¢
  <a href="#quick-start">Quick Start</a> â€¢
  <a href="#configuration">Configuration</a> â€¢
  <a href="#deployment">Deployment</a> â€¢
  <a href="#architecture">Architecture</a> â€¢
  <a href="#contributing">Contributing</a>
</p>

---

## ğŸ¯ Overview

Wonbiz AI is a sophisticated voice assistant application that combines speech recognition, AI-powered summarization, and vector search to create an intelligent note-taking experience. Record your thoughts, have them automatically transcribed and summarized, then search through your knowledge base using natural language.

## âœ¨ Features

### ğŸ™ï¸ Voice Recording & Transcription
- **Real-time audio recording** with visual feedback
- **AssemblyAI integration** for high-quality speech-to-text
- **Multi-format support** for various audio inputs

### ğŸ¤– AI-Powered Analysis
- **Multiple LLM providers**: OpenAI, Grok (xAI), and Gemini
- **Intelligent summarization** of audio content
- **Automatic tagging** and categorization
- **Context-aware processing** with LlamaIndex orchestration

### ğŸ” Vector Search & Knowledge Base
- **MongoDB Atlas Vector Search** for semantic search
- **Natural language queries** to find relevant notes
- **Hybrid search** combining vector and local filtering
- **Persistent storage** with cloud synchronization

### ğŸ’¬ Interactive Chat
- **Chat with your notes** using AI context
- **Follow-up questions** about recorded content
- **Conversation history** preservation

### ğŸ¨ Modern UI/UX
- **Responsive design** for desktop and mobile
- **Dark theme** with custom color scheme
- **Intuitive navigation** and user experience
- **Real-time processing indicators**

### âš™ï¸ Flexible Configuration
- **Provider selection** between OpenAI, Grok, and Gemini
- **Model switching** with multiple options per provider
- **API key management** through environment variables
- **Settings panel** for easy configuration

## ğŸš€ Quick Start

### Prerequisites

- **Node.js** 18+ and npm
- **API Keys** for your chosen LLM provider(s)
- **MongoDB Atlas** account (for vector search)
- **AssemblyAI** account (for transcription)
- **LlamaCloud** account (for orchestration)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/softbread/wonbiz-ai.git
   cd wonbiz-ai
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Configure environment variables**
   ```bash
   cp .env.example .env
   ```

   Edit `.env` with your API keys:
   ```env
   # Choose your LLM provider
   VITE_OPENAI_API_KEY=your_openai_key
   VITE_GROK_API_KEY=your_grok_key
   VITE_GEMINI_API_KEY=your_gemini_key

   # Required services
   VITE_ASSEMBLYAI_API_KEY=your_assemblyai_key
   VITE_LLAMA_CLOUD_API_KEY=your_llama_cloud_key

   # MongoDB Atlas Vector Search
   VITE_MONGODB_DATA_API_URL=https://data.mongodb-api.com/app/YOUR_APP_ID/endpoint/data/v1
   VITE_MONGODB_DATA_API_KEY=your_mongodb_key
   VITE_MONGODB_DATA_SOURCE=your_cluster
   VITE_MONGODB_VECTOR_DB=your_database
   VITE_MONGODB_VECTOR_COLLECTION=your_collection
   VITE_MONGODB_VECTOR_INDEX=your_vector_index
   ```

4. **Start the development server**
   ```bash
   npm run dev
   ```

5. **Open your browser**
   ```
   http://localhost:3000
   ```

## ğŸ³ Docker Deployment

### Development Environment
```bash
# Start development container with hot reload
docker-compose --profile dev up --build
```

### Production Deployment
```bash
# Build and run production container
docker-compose --profile prod up --build -d
```

Access the production app at `http://localhost:80`

## âš™ï¸ Configuration

### LLM Providers

Choose from three AI providers with multiple models:

| Provider | Models | Best For |
|----------|--------|----------|
| **OpenAI OSS** | `openai-oss`, `openai-oss-mini` | Balanced performance |
| **Grok 4.1** | `grok-4.1-fast`, `grok-4.1`, `grok-4.1-mini` | Fast responses |
| **Gemini 3** | `gemini-3`, `gemini-3-flash`, `gemini-3-pro` | Multimodal tasks |

### Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `VITE_OPENAI_API_KEY` | OpenAI API key | Optional* |
| `VITE_GROK_API_KEY` | Grok (xAI) API key | Optional* |
| `VITE_GEMINI_API_KEY` | Gemini API key | Optional* |
| `VITE_ASSEMBLYAI_API_KEY` | AssemblyAI transcription key | Yes |
| `VITE_LLAMA_CLOUD_API_KEY` | LlamaIndex Cloud API key | Yes |
| `VITE_MONGODB_DATA_API_URL` | MongoDB Atlas Data API URL | Yes |
| `VITE_MONGODB_DATA_API_KEY` | MongoDB Atlas API key | Yes |
| `VITE_MONGODB_DATA_SOURCE` | MongoDB cluster name | Yes |
| `VITE_MONGODB_VECTOR_DB` | Vector database name | Yes |
| `VITE_MONGODB_VECTOR_COLLECTION` | Vector collection name | Yes |
| `VITE_MONGODB_VECTOR_INDEX` | Vector search index name | Yes |
| `VITE_EMBEDDING_MODEL` | Embedding model (default: `text-embedding-3-small`) | No |

*At least one LLM provider API key is required

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React App     â”‚    â”‚   Vite Build    â”‚    â”‚   Nginx Server  â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Voice Recorderâ”‚    â”‚ â€¢ Environment   â”‚    â”‚ â€¢ Static Files  â”‚
â”‚ â€¢ Settings UI   â”‚    â”‚ â€¢ API Keys      â”‚    â”‚ â€¢ SPA Routing   â”‚
â”‚ â€¢ Note Display  â”‚    â”‚ â€¢ Optimization  â”‚    â”‚ â€¢ Compression   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  AI Services    â”‚
                    â”‚                 â”‚
                    â”‚ â€¢ AssemblyAI    â”‚
                    â”‚ â€¢ LlamaIndex    â”‚
                    â”‚ â€¢ LLM Providers â”‚
                    â”‚ â€¢ MongoDB Atlas â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

1. **Recording** â†’ Audio blob captured
2. **Transcription** â†’ AssemblyAI processes audio
3. **Analysis** â†’ LlamaIndex orchestrates summarization
4. **Embedding** â†’ Text converted to vectors
5. **Storage** â†’ Note saved to MongoDB Atlas
6. **Search** â†’ Vector search finds relevant notes

## ğŸ“± Usage

### Recording Notes
1. Click the **"New Note"** button (microphone icon)
2. Grant microphone permissions
3. Record your thoughts
4. Processing happens automatically:
   - Transcription
   - Summarization
   - Tagging
   - Vector embedding

### Searching Notes
- Use the search bar for **vector search** across all notes
- Results combine semantic search with local filtering
- Click any note to view details and chat

### Configuring AI Models
1. Click **"Settings"** in the sidebar
2. Choose your preferred LLM provider
3. Select a specific model
4. Check API key status
5. Save changes

### Chatting with Notes
1. Open any note detail view
2. Ask questions about the content
3. AI responds with context from the transcript

## ğŸ”§ Development

### Project Structure
```
wonbiz-ai/
â”œâ”€â”€ components/          # React components
â”‚   â”œâ”€â”€ Icons.tsx       # SVG icons
â”‚   â”œâ”€â”€ NoteDetail.tsx  # Note viewing & chat
â”‚   â”œâ”€â”€ NoteList.tsx    # Note grid display
â”‚   â”œâ”€â”€ Recorder.tsx    # Audio recording UI
â”‚   â””â”€â”€ Settings.tsx    # Configuration modal
â”œâ”€â”€ services/           # API integrations
â”‚   â”œâ”€â”€ assistantService.ts  # Main orchestration
â”‚   â”œâ”€â”€ audioUtils.ts   # Audio processing
â”‚   â””â”€â”€ geminiService.ts     # Gemini-specific logic
â”œâ”€â”€ types.ts           # TypeScript definitions
â”œâ”€â”€ App.tsx           # Main application
â”œâ”€â”€ main.tsx         # React entry point
â””â”€â”€ vite.config.ts   # Build configuration
```

### Available Scripts

| Command | Description |
|---------|-------------|
| `npm run dev` | Start development server |
| `npm run build` | Build for production |
| `npm run preview` | Preview production build |

### Key Technologies

- **Frontend**: React 19, TypeScript, Vite
- **Styling**: Tailwind CSS (custom theme)
- **Audio**: Web Audio API, MediaRecorder
- **AI Services**: AssemblyAI, LlamaIndex, Multiple LLMs
- **Database**: MongoDB Atlas with Vector Search
- **Deployment**: Docker, nginx

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Commit changes: `git commit -m 'Add amazing feature'`
4. Push to branch: `git push origin feature/amazing-feature`
5. Open a Pull Request

### Development Guidelines

- Use TypeScript for all new code
- Follow React best practices
- Test API integrations thoroughly
- Update documentation for new features
- Ensure Docker compatibility

## ğŸ“„ License

This project is private and proprietary.

## ğŸ™ Acknowledgments

- **AssemblyAI** for speech-to-text transcription
- **LlamaIndex** for AI orchestration
- **MongoDB Atlas** for vector search capabilities
- **OpenAI, xAI, Google** for LLM APIs
- **React & Vite** communities for excellent tooling

---

<p align="center">
  Made with â¤ï¸ using modern AI and web technologies
</p>
